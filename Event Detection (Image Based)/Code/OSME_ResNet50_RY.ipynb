{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "OSME_ResNet50_RY.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "An4CdfiwIepO"
      },
      "source": [
        "import os\n",
        "save_directory= \"Model\"\n",
        "train_address = \"Train\"\n",
        "test_address = \"Test\"\n",
        "\n",
        "if not os.path.exists(test_address):\n",
        "  os.makedirs(test_address)\n",
        "  !wget -q https://raw.githubusercontent.com/circulosmeos/gdown.pl/master/gdown.pl -O gdown.pl\n",
        "  !pip install efficientnet\n",
        "  !perl gdown.pl \"https://drive.google.com/u/0/uc?export=download&confirm=n51E&id=1rxlpshNKP2gQ6NP9Wpvq-jUdbk5t6-Ub\" \"Red-Cards.zip\"\n",
        "  !unzip Red-Cards.zip\n",
        "  !mv Red-Cards Test/Red-Cards\n",
        "  !perl gdown.pl \"https://drive.google.com/u/0/uc?export=download&confirm=Ez4P&id=1tvWzG3stQaY6fqs8O6F_3Ec_qguZU3mC\" \"Yellow-Cards.zip\"\n",
        "  !unzip Yellow-Cards.zip\n",
        "  !mv Yellow-Cards Test/Yellow-Cards\n",
        "\n",
        "if not os.path.exists(train_address):\n",
        "  os.makedirs(train_address)\n",
        "  !perl gdown.pl \"https://drive.google.com/u/0/uc?export=download&confirm=nJ31&id=1sQuc6JoE5CoKq6JYe6i75AoWEBngAVb8\" \"Red-Cards.zip\"\n",
        "  !unzip Red-Cards.zip\n",
        "  !mv Red-Cards Train/Red-Cards\n",
        "  !perl gdown.pl \"https://drive.google.com/u/0/uc?export=download&confirm=vrjS&id=1IozEkL1xhRoG9oqnBvdozrlTcTsqk9s6\" \"Yellow-Cards.zip\"\n",
        "  !unzip Yellow-Cards.zip\n",
        "  !mv Yellow-Cards Train/Yellow-Cards\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3qFYDhahPdWK"
      },
      "source": [
        "\n",
        "import keras\n",
        "from keras.callbacks import EarlyStopping\n",
        "from keras.applications.resnet50 import ResNet50\n",
        "from keras.applications.vgg19 import VGG19\n",
        "from keras.models import Model\n",
        "from keras.layers import Input, Dense, Flatten, Multiply, add\n",
        "from keras.layers import GlobalAveragePooling2D\n",
        "from keras.callbacks import ModelCheckpoint, LearningRateScheduler, ReduceLROnPlateau\n",
        "from keras.optimizers import SGD\n",
        "from keras.utils.np_utils import to_categorical\n",
        "from keras.preprocessing.image import ImageDataGenerator, load_img, img_to_array\n",
        "from keras.regularizers import l2\n",
        "import matplotlib.image as mpimg\n",
        "import numpy as np\n",
        "import keras.backend as K\n",
        "import pathlib\n",
        "from PIL import Image\n",
        "import cv2\n",
        "from sklearn.preprocessing import OneHotEncoder, LabelEncoder\n",
        "import matplotlib.pyplot as plt\n",
        "from keras.utils.vis_utils import plot_model\n",
        "import pandas as pd\n",
        "import os\n",
        "from keras.optimizers import Adam,RMSprop, SGD , Nadam, Adadelta\n",
        "BATCH_SIZE = 16\n",
        "test_nb = 1000\n",
        "train_nb = 11000\n",
        "num_classes = 2\n",
        "img_size= 224\n",
        "classes = []\n",
        "\n",
        "train_path = \"Train\"\n",
        "test_path = \"Test\"\n",
        "\n",
        "\n",
        "\n",
        "train_datagen = ImageDataGenerator(rescale = 1.0/255, \n",
        "                                   zoom_range=[1.0,2.0],\n",
        "                                   rotation_range=90,\n",
        "                                   horizontal_flip=True,\n",
        "                                   vertical_flip=True)\n",
        "test_datagen = ImageDataGenerator(rescale = 1.0/255)\n",
        "\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "        train_path,\n",
        "        target_size=(img_size, img_size),\n",
        "        batch_size=BATCH_SIZE,\n",
        "        seed = 13)\n",
        "\n",
        "validation_generator = test_datagen.flow_from_directory(\n",
        "        test_path,\n",
        "        target_size=(img_size, img_size),\n",
        "        batch_size=BATCH_SIZE,\n",
        "        seed = 13)\n",
        "\n",
        "input_tensor = Input(shape=(img_size, img_size, 3))\n",
        "base_model = ResNet50(weights = \"imagenet\", include_top=False, input_tensor=input_tensor)\n",
        "def osme_block(in_block, ch, ratio=16):\n",
        "    z = GlobalAveragePooling2D()(in_block) # 1\n",
        "    x = Dense(ch//ratio, activation='relu')(z) # 2\n",
        "    x = Dense(ch, activation='sigmoid')(x) # 3\n",
        "    return Multiply()([in_block, x]) # 4\n",
        "\n",
        "s_1 = osme_block(base_model.output, base_model.output_shape[3])\n",
        "s_2 = osme_block(base_model.output, base_model.output_shape[3])\n",
        "\n",
        "fc1 = Flatten()(s_1)\n",
        "fc2 = Flatten()(s_2)\n",
        "\n",
        "fc1 = Dense(1024, name='fc1')(fc1)\n",
        "fc2 = Dense(1024, name='fc2')(fc2)\n",
        "\n",
        "\n",
        "fc = add([fc1,fc2]) # fc1 + fc2\n",
        "\n",
        "prediction = Dense(num_classes, activation='softmax', name='prediction')(fc)\n",
        "\n",
        "\n",
        "model = Model(inputs=base_model.input, outputs=prediction)\n",
        "\n",
        "opt = Adam(lr=0.001,  decay=0.0001)\n",
        "\n",
        "    \n",
        "model.compile(optimizer=\"Adam\", loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "\n",
        "\n",
        "history = model.fit_generator(train_generator,\n",
        "                    steps_per_epoch=train_nb/ 16 ,\n",
        "                    epochs=60,\n",
        "                    validation_data=validation_generator,\n",
        "                    validation_steps=int(test_nb/16),\n",
        "                    verbose=1)  \n",
        "\n",
        "import datetime\n",
        "now = datetime.datetime.now()\n",
        "model.evaluate(validation_generator)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zr1QyA3fXzOi"
      },
      "source": [
        "plt.plot(history.history['accuracy'])\n",
        "plt.plot(history.history['val_accuracy'])\n",
        "plt.title('model accuracy')\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'test'], loc='upper left')\n",
        "plt.savefig(\"model accuracy\")\n",
        "plt.show()\n",
        "\n",
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.title('model loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'test'], loc='upper left')\n",
        "plt.savefig(\"model loss\")\n",
        "\n",
        "print(\"[INFO] serializing network...\")\n",
        "model.save(\"model_saved\")"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}